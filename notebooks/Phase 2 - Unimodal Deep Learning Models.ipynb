{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 - Unimodal Deep Learning Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 17:45:19,251 - INFO - Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "## Import required libraries and modules\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import importlib\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"src\")))\n",
    "\n",
    "\n",
    "from utils import load_config\n",
    "from preprocess.preprocess import split_data\n",
    "from models import FlexibleFCNN\n",
    "from pipelines import DLModelsPipeline\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Load Config\n",
    "config = load_config(\"../config.yaml\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 17:45:19,273 - INFO - Loading datasets...\n",
      "2024-12-14 17:45:30,820 - INFO - Loading gene dataset in chunks...\n",
      "2024-12-14 17:47:05,070 - INFO - Splitting datasets into train/val/test...\n"
     ]
    }
   ],
   "source": [
    "## Load, Split and Preprocess Dataset\n",
    "# Load datasets\n",
    "logging.info(\"Loading datasets...\")\n",
    "tf_df = pd.read_csv(config[\"data_paths\"][\"preprocessed_tf_file\"])\n",
    "landmark_df = pd.read_csv(config[\"data_paths\"][\"preprocessed_landmark_file\"])\n",
    "\n",
    "# For large gene data, read in chunks\n",
    "logging.info(\"Loading gene dataset in chunks...\")\n",
    "chunk_size = 1000\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(\n",
    "    config[\"data_paths\"][\"preprocessed_gene_file\"], chunksize=chunk_size\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "gene_df = pd.concat(chunks, axis=0)\n",
    "del chunks  # Free memory\n",
    "\n",
    "# # Only sample 1000 rows for now\n",
    "# tf_df = tf_df.sample(1000)\n",
    "# landmark_df = landmark_df.sample(1000)\n",
    "# gene_df = gene_df.sample(1000)\n",
    "\n",
    "# Split Data\n",
    "logging.info(\"Splitting datasets into train/val/test...\")\n",
    "X_tf_train, y_tf_train, X_tf_val, y_tf_val, X_tf_test, y_tf_test = split_data(\n",
    "    tf_df, target_name=\"viability\", config=config\n",
    ")\n",
    "(\n",
    "    X_landmark_train,\n",
    "    y_landmark_train,\n",
    "    X_landmark_val,\n",
    "    y_landmark_val,\n",
    "    X_landmark_test,\n",
    "    y_landmark_test,\n",
    ") = split_data(landmark_df, target_name=\"viability\", config=config)\n",
    "X_gene_train, y_gene_train, X_gene_val, y_gene_val, X_gene_test, y_gene_test = (\n",
    "    split_data(gene_df, target_name=\"viability\", config=config)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 17:47:14,819 - INFO - Creating DataLoaders...\n"
     ]
    }
   ],
   "source": [
    "def create_dataloader(X, y, batch_size=32):\n",
    "    # Ensuring X and y are pandas DataFrames/Series:\n",
    "    # If they are arrays, adjust accordingly.\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(X.values, dtype=torch.float32),\n",
    "        torch.tensor(y.values, dtype=torch.float32),\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "logging.info(\"Creating DataLoaders...\")\n",
    "tf_train_loader = create_dataloader(X_tf_train, y_tf_train)\n",
    "tf_val_loader = create_dataloader(X_tf_val, y_tf_val)\n",
    "tf_test_loader = create_dataloader(X_tf_test, y_tf_test)\n",
    "\n",
    "landmark_train_loader = create_dataloader(X_landmark_train, y_landmark_train)\n",
    "landmark_val_loader = create_dataloader(X_landmark_val, y_landmark_val)\n",
    "landmark_test_loader = create_dataloader(X_landmark_test, y_landmark_test)\n",
    "\n",
    "gene_train_loader = create_dataloader(X_gene_train, y_gene_train)\n",
    "gene_val_loader = create_dataloader(X_gene_val, y_gene_val)\n",
    "gene_test_loader = create_dataloader(X_gene_test, y_gene_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CNNRegressor, MLPMixer, TransformerRegressor\n",
    "\n",
    "\n",
    "feature_sets = {\n",
    "    \"TF Data\": (tf_train_loader, tf_val_loader, tf_test_loader),\n",
    "    \"Landmark Data\": (landmark_train_loader, landmark_val_loader, landmark_test_loader),\n",
    "    # \"Gene Data\": (gene_train_loader, gene_val_loader, gene_test_loader),\n",
    "}\n",
    "\n",
    "# Define your model configurations\n",
    "model_configs = {\n",
    "    \"FCNN_Model\": {\n",
    "        \"model_class\": FlexibleFCNN,\n",
    "        \"model_params\": {\n",
    "            \"hidden_dims\": [512, 256, 128, 64],\n",
    "            \"output_dim\": 1,\n",
    "            \"activation_fn\": \"prelu\",\n",
    "            \"dropout_prob\": 0.2,\n",
    "            \"residual\": True,\n",
    "            \"norm_type\": \"batchnorm\",\n",
    "            \"weight_init\": \"xavier\",\n",
    "        },\n",
    "        \"criterion\": nn.MSELoss(),\n",
    "        \"optimizer_class\": optim.AdamW,\n",
    "        \"optimizer_params\": {\"lr\": 0.001, \"weight_decay\": 1e-4},\n",
    "        \"scheduler_class\": ReduceLROnPlateau,\n",
    "        \"scheduler_params\": {\"mode\": \"min\", \"patience\": 5},\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 10,\n",
    "            \"gradient_clipping\": 1.0,\n",
    "            \"early_stopping_patience\": 10,\n",
    "        },\n",
    "    },\n",
    "    \"Transformer_Model\": {\n",
    "        \"model_class\": TransformerRegressor,\n",
    "        \"model_params\": {\n",
    "            \"d_model\": 128,\n",
    "            \"nhead\": 4,\n",
    "            \"num_layers\": 2,\n",
    "            \"dim_feedforward\": 256,\n",
    "            \"dropout\": 0.1,\n",
    "            \"output_dim\": 1,\n",
    "        },\n",
    "        \"criterion\": nn.MSELoss(),\n",
    "        \"optimizer_class\": optim.AdamW,\n",
    "        \"optimizer_params\": {\"lr\": 0.001, \"weight_decay\": 1e-4},\n",
    "        \"scheduler_class\": ReduceLROnPlateau,\n",
    "        \"scheduler_params\": {\"mode\": \"min\", \"patience\": 5},\n",
    "        \"train_params\": {\n",
    "            \"epochs\": 10,\n",
    "            \"gradient_clipping\": 1.0,\n",
    "            \"early_stopping_patience\": 10,\n",
    "        },\n",
    "    },\n",
    "    # \"CNN_Model\": {\n",
    "    #     \"model_class\": CNNRegressor,\n",
    "    #     \"model_params\": {\n",
    "    #         \"num_filters\": 64,\n",
    "    #         \"kernel_size\": 7,\n",
    "    #         \"num_layers\": 3,\n",
    "    #         \"dropout_prob\": 0.2,\n",
    "    #         \"output_dim\": 1,\n",
    "    #     },\n",
    "    #     \"criterion\": nn.MSELoss(),\n",
    "    #     \"optimizer_class\": optim.AdamW,\n",
    "    #     \"optimizer_params\": {\"lr\": 0.001, \"weight_decay\": 1e-4},\n",
    "    #     \"scheduler_class\": ReduceLROnPlateau,\n",
    "    #     \"scheduler_params\": {\"mode\": \"min\", \"patience\": 5},\n",
    "    #     \"train_params\": {\n",
    "    #         \"epochs\": 10,\n",
    "    #         \"gradient_clipping\": 1.0,\n",
    "    #         \"early_stopping_patience\": 10,\n",
    "    #     },\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now initialize the pipeline using model_configs instead of model_class & model_params\n",
    "pipeline = DLModelsPipeline(feature_sets=feature_sets, model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-14 17:47:17,468 - INFO - Starting training and evaluation...\n",
      "2024-12-14 17:47:29,614 - INFO - Epoch 1/10 - Model, Train Loss: 0.2286, Val Loss: 0.0345\n",
      "2024-12-14 17:47:35,794 - INFO - Epoch 2/10 - Model, Train Loss: 0.0407, Val Loss: 0.0303\n",
      "2024-12-14 17:47:42,162 - INFO - Epoch 3/10 - Model, Train Loss: 0.0340, Val Loss: 0.0305\n",
      "2024-12-14 17:47:48,468 - INFO - Epoch 4/10 - Model, Train Loss: 0.0306, Val Loss: 0.0287\n",
      "2024-12-14 17:47:54,649 - INFO - Epoch 5/10 - Model, Train Loss: 0.0286, Val Loss: 0.0295\n",
      "2024-12-14 17:48:00,938 - INFO - Epoch 6/10 - Model, Train Loss: 0.0266, Val Loss: 0.0279\n",
      "2024-12-14 17:48:07,600 - INFO - Epoch 7/10 - Model, Train Loss: 0.0248, Val Loss: 0.0275\n",
      "2024-12-14 17:48:13,814 - INFO - Epoch 8/10 - Model, Train Loss: 0.0230, Val Loss: 0.0276\n",
      "2024-12-14 17:48:19,824 - INFO - Epoch 9/10 - Model, Train Loss: 0.0218, Val Loss: 0.0275\n",
      "2024-12-14 17:48:26,054 - INFO - Epoch 10/10 - Model, Train Loss: 0.0204, Val Loss: 0.0286\n",
      "2024-12-14 17:50:06,669 - INFO - Epoch 1/10 - Model, Train Loss: 0.0958, Val Loss: 0.0697\n",
      "2024-12-14 17:51:47,323 - INFO - Epoch 2/10 - Model, Train Loss: 0.0466, Val Loss: 0.0498\n",
      "2024-12-14 17:53:28,390 - INFO - Epoch 3/10 - Model, Train Loss: 0.0426, Val Loss: 0.0412\n",
      "2024-12-14 17:55:09,374 - INFO - Epoch 4/10 - Model, Train Loss: 0.0406, Val Loss: 0.0392\n",
      "2024-12-14 17:56:49,813 - INFO - Epoch 5/10 - Model, Train Loss: 0.0392, Val Loss: 0.0405\n",
      "2024-12-14 17:58:31,111 - INFO - Epoch 6/10 - Model, Train Loss: 0.0391, Val Loss: 0.0390\n",
      "2024-12-14 18:00:11,312 - INFO - Epoch 7/10 - Model, Train Loss: 0.0389, Val Loss: 0.0381\n",
      "2024-12-14 18:01:51,409 - INFO - Epoch 8/10 - Model, Train Loss: 0.0376, Val Loss: 0.0385\n",
      "2024-12-14 18:03:31,714 - INFO - Epoch 9/10 - Model, Train Loss: 0.0378, Val Loss: 0.0404\n",
      "2024-12-14 18:05:14,120 - INFO - Epoch 10/10 - Model, Train Loss: 0.0374, Val Loss: 0.0375\n",
      "2024-12-14 18:05:28,417 - INFO - Epoch 1/10 - Model, Train Loss: 0.1962, Val Loss: 0.0367\n",
      "2024-12-14 18:05:37,463 - INFO - Epoch 2/10 - Model, Train Loss: 0.0436, Val Loss: 0.0335\n",
      "2024-12-14 18:05:46,898 - INFO - Epoch 3/10 - Model, Train Loss: 0.0365, Val Loss: 0.0337\n",
      "2024-12-14 18:05:57,102 - INFO - Epoch 4/10 - Model, Train Loss: 0.0339, Val Loss: 0.0332\n",
      "2024-12-14 18:06:10,629 - INFO - Epoch 5/10 - Model, Train Loss: 0.0320, Val Loss: 0.0329\n",
      "2024-12-14 18:06:20,618 - INFO - Epoch 6/10 - Model, Train Loss: 0.0305, Val Loss: 0.0322\n",
      "2024-12-14 18:06:27,903 - INFO - Epoch 7/10 - Model, Train Loss: 0.0287, Val Loss: 0.0326\n",
      "2024-12-14 18:06:35,409 - INFO - Epoch 8/10 - Model, Train Loss: 0.0265, Val Loss: 0.0318\n",
      "2024-12-14 18:06:43,032 - INFO - Epoch 9/10 - Model, Train Loss: 0.0253, Val Loss: 0.0330\n",
      "2024-12-14 18:06:53,383 - INFO - Epoch 10/10 - Model, Train Loss: 0.0232, Val Loss: 0.0314\n",
      "2024-12-14 18:09:16,467 - INFO - Epoch 1/10 - Model, Train Loss: 0.0689, Val Loss: 0.0472\n",
      "2024-12-14 18:11:41,320 - INFO - Epoch 2/10 - Model, Train Loss: 0.0460, Val Loss: 0.0460\n",
      "2024-12-14 18:14:05,402 - INFO - Epoch 3/10 - Model, Train Loss: 0.0442, Val Loss: 0.0459\n",
      "2024-12-14 18:16:28,337 - INFO - Epoch 4/10 - Model, Train Loss: 0.0424, Val Loss: 0.0434\n",
      "2024-12-14 18:18:50,514 - INFO - Epoch 5/10 - Model, Train Loss: 0.0410, Val Loss: 0.0426\n",
      "2024-12-14 18:21:12,793 - INFO - Epoch 6/10 - Model, Train Loss: 0.0406, Val Loss: 0.0435\n",
      "2024-12-14 18:23:34,920 - INFO - Epoch 7/10 - Model, Train Loss: 0.0394, Val Loss: 0.0389\n",
      "2024-12-14 18:25:57,253 - INFO - Epoch 8/10 - Model, Train Loss: 0.0385, Val Loss: 0.0422\n",
      "2024-12-14 18:28:19,804 - INFO - Epoch 9/10 - Model, Train Loss: 0.0399, Val Loss: 0.0443\n",
      "2024-12-14 18:30:42,024 - INFO - Epoch 10/10 - Model, Train Loss: 0.0384, Val Loss: 0.0411\n",
      "2024-12-14 18:30:46,759 - INFO - Collecting results...\n",
      "2024-12-14 18:30:46,880 - INFO - Results saved to combined_metrics.csv.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "logging.info(\"Starting training and evaluation...\")\n",
    "pipeline.train_and_evaluate()\n",
    "\n",
    "# Retrieve results\n",
    "logging.info(\"Collecting results...\")\n",
    "results_df = pipeline.get_results()\n",
    "\n",
    "# Save the results\n",
    "results_df.to_csv(\"combined_metrics.csv\", index=False)\n",
    "logging.info(\"Results saved to combined_metrics.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2d1aa_row2_col0, #T_2d1aa_row2_col1, #T_2d1aa_row2_col2, #T_2d1aa_row2_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2d1aa\">\n",
       "  <caption>Regression Model Evaluation Metrics</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2d1aa_level0_col0\" class=\"col_heading level0 col0\" >MSE</th>\n",
       "      <th id=\"T_2d1aa_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_2d1aa_level0_col2\" class=\"col_heading level0 col2\" >R²</th>\n",
       "      <th id=\"T_2d1aa_level0_col3\" class=\"col_heading level0 col3\" >Pearson Correlation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Feature Set</th>\n",
       "      <th class=\"index_name level1\" >Model Name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2d1aa_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Landmark Data</th>\n",
       "      <th id=\"T_2d1aa_level1_row0\" class=\"row_heading level1 row0\" >FCNN_Model</th>\n",
       "      <td id=\"T_2d1aa_row0_col0\" class=\"data row0 col0\" >0.032</td>\n",
       "      <td id=\"T_2d1aa_row0_col1\" class=\"data row0 col1\" >0.109</td>\n",
       "      <td id=\"T_2d1aa_row0_col2\" class=\"data row0 col2\" >0.438</td>\n",
       "      <td id=\"T_2d1aa_row0_col3\" class=\"data row0 col3\" >0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d1aa_level1_row1\" class=\"row_heading level1 row1\" >Transformer_Model</th>\n",
       "      <td id=\"T_2d1aa_row1_col0\" class=\"data row1 col0\" >0.038</td>\n",
       "      <td id=\"T_2d1aa_row1_col1\" class=\"data row1 col1\" >0.133</td>\n",
       "      <td id=\"T_2d1aa_row1_col2\" class=\"data row1 col2\" >0.340</td>\n",
       "      <td id=\"T_2d1aa_row1_col3\" class=\"data row1 col3\" >0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d1aa_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">TF Data</th>\n",
       "      <th id=\"T_2d1aa_level1_row2\" class=\"row_heading level1 row2\" >FCNN_Model</th>\n",
       "      <td id=\"T_2d1aa_row2_col0\" class=\"data row2 col0\" >0.028</td>\n",
       "      <td id=\"T_2d1aa_row2_col1\" class=\"data row2 col1\" >0.097</td>\n",
       "      <td id=\"T_2d1aa_row2_col2\" class=\"data row2 col2\" >0.518</td>\n",
       "      <td id=\"T_2d1aa_row2_col3\" class=\"data row2 col3\" >0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2d1aa_level1_row3\" class=\"row_heading level1 row3\" >Transformer_Model</th>\n",
       "      <td id=\"T_2d1aa_row3_col0\" class=\"data row3 col0\" >0.038</td>\n",
       "      <td id=\"T_2d1aa_row3_col1\" class=\"data row3 col1\" >0.136</td>\n",
       "      <td id=\"T_2d1aa_row3_col2\" class=\"data row3 col2\" >0.345</td>\n",
       "      <td id=\"T_2d1aa_row3_col3\" class=\"data row3 col3\" >0.593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21892dc7df0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_results = (\n",
    "    results_df.style.format(precision=3)\n",
    "    .set_caption(\"Regression Model Evaluation Metrics\")\n",
    "    .highlight_max(\n",
    "        subset=[\"R²\", \"Pearson Correlation\"], color=\"lightgreen\"\n",
    "    )\n",
    "    .highlight_min(subset=[\"MAE\", \"MSE\"], color=\"lightgreen\")\n",
    ")\n",
    "styled_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5ARG45",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
