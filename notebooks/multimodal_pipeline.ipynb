{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Training Pipeline Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Import all needed libraries, custom functionality and models. When a package is not found use:\n",
    "\n",
    "`pip install \"package\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\20191678\\AppData\\Local\\miniconda3\\envs\\5ARG45\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "c:\\Users\\20191678\\AppData\\Local\\miniconda3\\envs\\5ARG45\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Kan opgegeven procedure niet vinden'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\20191678\\AppData\\Local\\miniconda3\\envs\\5ARG45\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\20191678\\AppData\\Local\\miniconda3\\envs\\5ARG45\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocess.molecule_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4044/2971218783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartition_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmolecule_graph\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmol_to_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_sets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMoleculeDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTranscriptomicsDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultimodalDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocess.molecule_graph'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from deepchem.feat.molecule_featurizers import MolGraphConvFeaturizer\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from preprocess.preprocess import partition_data,load_config, preprocess_data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from preprocess.molecule_graph import mol_to_graph\n",
    "from preprocess.data_sets import MoleculeDataset, TranscriptomicsDataset, MultimodalDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.gnn import GNN\n",
    "from models.multimodal_nn import MultimodalNN\n",
    "from models.transcriptomics_nn import TranscriptomicsNN\n",
    "from training.train_multimodal import train_multimodal_model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from utils.evaluation import evaluate_regression_metrics\n",
    "\n",
    "import torch\n",
    "from models.unimodal import CNN, FFNN\n",
    "from training.train_unimodal import train_unimodal_model, evaluate_unimodal_model\n",
    "from visualizations.visualizations import (\n",
    "    create_visualizations,\n",
    "    plot_loss_curves,\n",
    "    plot_predictions_combined,\n",
    "    plot_residuals_combined,\n",
    "    plot_error_boxplots,\n",
    ")\n",
    "from torch.utils.data import DataLoader \n",
    "from training.train_shallow import evaluate_shallow_model\n",
    "from torch_geometric.loader import DataLoader as GeometricDataLoader\n",
    "\n",
    "from preprocess.preprocess import preprocess_tf_data, preprocess_gene_data\n",
    "\n",
    "import preprocess\n",
    "importlib.reload(preprocess)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess Data\n",
    "\n",
    "In this step the data is processed from the raw .tsv/.csv files of chemical compounds, transcriptomic TF data and the viability target. The data is located in the `data/raw` folder:\n",
    "- `compoundinfo.csv`: Chemical compounds with their SMILES representation and an unique ID for each pertubation compound.\n",
    "- `X.tsv`: Unique pertubation experiments per row with their corresponding changes in TF gene expression.\n",
    "- `Y.tsv`: Pertubation experiment outcomes linking a cell line with an unqiue pertubation compound and its concentration with their viability score as experiment outcome.\n",
    "\n",
    "All the preprocessing is encapsulated in the hih level `preprocess_data` function that does the following in consecutive order:\n",
    "1. Load the 3 raw data tables from their paths specified in the `config.yaml` file (This allows for easier adaptation and best MLOps practices)\n",
    "2. The tables are merged by a table join on the compound ID and cell line experiment ID. This results in a single `pd.Dataframe` that has on each row the compound information, the TF gene expression data and the viability score.\n",
    "3. The resulting `pd.Dataframe` is evaluated on missing values, when present the complete row is removed. If it turns out that a lot of rows are removed, data imputation might be a better option.\n",
    "4. TF gene expression data is standardized to have zero mean and a standard deviation of 1 to stabilize training in later steps.\n",
    "5. The merged and processed data is then saved to `data/processed` as `final_dataset.csv`.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_config\n",
    "\n",
    "config = load_config(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we can simply load in this merged dataset using Pandas. We select the first 1000 rows of the 30.000 for faster code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and load the data\n",
    "tf_df = preprocess_tf_data(config, standardize=True)\n",
    "gene_df = preprocess_gene_data(config, standardize=True, use_landmarks=True)\n",
    "\n",
    "logging.debug(f\"TF data shape: {tf_df.shape}, Gene data shape: {gene_df.shape}\")\n",
    "\n",
    "# Only select the first 1000 rows for easy handling\n",
    "tf_df = tf_df.iloc[:1000]\n",
    "gene_df = gene_df.iloc[:1000]\n",
    "\n",
    "# Load the data\n",
    "# combined_df = pd.read_csv(\"../data/processed/final_dataset.csv\")\n",
    "\n",
    "# Only select the first 1000 rows for easy handling\n",
    "# combined_df = combined_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the data into training testing and validation sets. This allows for hyperparameter tuning and model evaluation in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split sizes\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.45\n",
    "test_ratio = 0.05\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "    tf_df, test_size=1 - train_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into validation and test\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=test_ratio / (test_ratio + val_ratio), random_state=42\n",
    ")\n",
    "\n",
    "# Split the datasets into features and labels (X, y)\n",
    "X_train, y_train = train_df.drop(\"viability\", axis=1), train_df[\"viability\"]\n",
    "X_val, y_val = val_df.drop(\"viability\", axis=1), val_df[\"viability\"]\n",
    "X_test, y_test = test_df.drop(\"viability\", axis=1), test_df[\"viability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Benchmarking on Unimodal Information\n",
    "\n",
    "Before approaching multimodal learning, we need to test wheter or not it is even needed. In other words, how accurate can we predict the viability score from the TF gene epxression alone? Additionally, how complex is this learning task? Therefore, we will first train and evaluate simple (shallow and/or linear) models to set a benchmark for later deep and multimodal models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Simple Unimodal ML Models for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.01),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Train, evaluate, and collect results\n",
    "for name, model in models.items():\n",
    "    print(f\"Training and Evaluating {name}...\")\n",
    "\n",
    "    # Fit the model on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, y_true, y_pred, metrics = evaluate_shallow_model(\n",
    "        model, X_test, y_test, calculate_metrics=True\n",
    "    )\n",
    "\n",
    "    # Store evaluation results\n",
    "    results[name] = {\n",
    "        \"Test Loss\": test_loss,\n",
    "        \"MSE\": metrics[\"MSE\"],\n",
    "        \"MAE\": metrics[\"MAE\"],\n",
    "        \"R²\": metrics[\"R²\"],\n",
    "        \"Pearson Correlation\": metrics[\"Pearson Correlation\"],\n",
    "    }\n",
    "\n",
    "# Display results in a DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "# Generate visualizations\n",
    "create_visualizations(models=models, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Unimodal Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_tf_dataset = TranscriptomicsDataset(\n",
    "    X_train, y_train\n",
    ")\n",
    "train_trans_loader = DataLoader(train_tf_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Validation set\n",
    "val_tf_dataset = TranscriptomicsDataset(\n",
    "    X_val, y_val\n",
    ")\n",
    "val_trans_loader = DataLoader(val_tf_dataset, batch_size=32)\n",
    "\n",
    "# Test set\n",
    "test_tf_dataset = TranscriptomicsDataset(\n",
    "    X_test, y_test\n",
    ")\n",
    "test_trans_loader = DataLoader(test_tf_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "ffnn = FFNN(input_dim=X_train.shape[1], hidden_dim=128, output_dim=1)\n",
    "cnn = CNN(input_dim=X_train.shape[1], hidden_dim=64, output_dim=1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.SmoothL1Loss()  # Huber Loss, robust to outliers\n",
    "ffnn_optimizer = torch.optim.AdamW(ffnn.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "cnn_optimizer = torch.optim.AdamW(cnn.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate schedulers\n",
    "ffnn_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    ffnn_optimizer, mode=\"min\", patience=3, factor=0.5\n",
    ")\n",
    "cnn_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    cnn_optimizer, mode=\"min\", patience=3, factor=0.5\n",
    ")\n",
    "\n",
    "# Train FFNN\n",
    "print(\"Training FFNN...\")\n",
    "ffnn_train_losses, ffnn_val_losses = train_unimodal_model(\n",
    "    ffnn,\n",
    "    train_trans_loader,\n",
    "    val_trans_loader,\n",
    "    criterion,\n",
    "    ffnn_optimizer,\n",
    "    ffnn_scheduler,\n",
    "    epochs=50,\n",
    "    device=device,\n",
    "    gradient_clipping=1.0,  # Prevent exploding gradients\n",
    "    early_stopping_patience=5,  # Stop early if no improvement\n",
    ")\n",
    "\n",
    "# Train CNN\n",
    "print(\"Training CNN...\")\n",
    "cnn_train_losses, cnn_val_losses = train_unimodal_model(\n",
    "    cnn,\n",
    "    train_trans_loader,\n",
    "    val_trans_loader,\n",
    "    criterion,\n",
    "    cnn_optimizer,\n",
    "    cnn_scheduler,\n",
    "    epochs=50,\n",
    "    device=device,\n",
    "    gradient_clipping=1.0,\n",
    "    early_stopping_patience=5,\n",
    ")\n",
    "\n",
    "# Evaluate FFNN\n",
    "print(\"Evaluating FFNN...\")\n",
    "ffnn_test_loss, ffnn_y_true, ffnn_y_pred, ffnn_metrics = evaluate_unimodal_model(\n",
    "    ffnn, test_trans_loader, criterion, device, calculate_metrics=True\n",
    ")\n",
    "print(\n",
    "    f\"FFNN Test Loss: {ffnn_test_loss:.4f}, \"\n",
    "    f\"MSE: {ffnn_metrics['MSE']:.4f}, \"\n",
    "    f\"MAE: {ffnn_metrics['MAE']:.4f}, \"\n",
    "    f\"R²: {ffnn_metrics['R²']:.4f}, \"\n",
    "    f\"Pearson: {ffnn_metrics['Pearson Correlation']:.4f}\"\n",
    ")\n",
    "\n",
    "# Evaluate CNN\n",
    "print(\"Evaluating CNN...\")\n",
    "cnn_test_loss, cnn_y_true, cnn_y_pred, cnn_metrics = evaluate_unimodal_model(\n",
    "    cnn, test_trans_loader, criterion, device, calculate_metrics=True\n",
    ")\n",
    "print(\n",
    "    f\"CNN Test Loss: {cnn_test_loss:.4f}, \"\n",
    "    f\"MSE: {cnn_metrics['MSE']:.4f}, \"\n",
    "    f\"MAE: {cnn_metrics['MAE']:.4f}, \"\n",
    "    f\"R²: {cnn_metrics['R²']:.4f}, \"\n",
    "    f\"Pearson: {cnn_metrics['Pearson Correlation']:.4f}\"\n",
    ")\n",
    "\n",
    "# # Create visualizations\n",
    "# create_visualizations(\n",
    "#     models={\"FFNN\": ffnn, \"CNN\": cnn},\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     train_losses={\"FFNN\": ffnn_train_losses, \"CNN\": cnn_train_losses},\n",
    "#     val_losses={\"FFNN\": ffnn_val_losses, \"CNN\": cnn_val_losses},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multimodal Model Design\n",
    "\n",
    "#### Separate Feature Extractors:\n",
    "We will use separate neural networks to extract latent features from each modality:\n",
    "- **Chemical Data (SMILES):** We will use Graph Neural Networks (GNNs) to process the SMILES representations of chemical compounds. GNNs are well-suited for capturing the structural as well as the hierarchical data information of molecules.\n",
    "- **Transcriptomics Data:** We will use autoencoders or other neural network architectures to process the TF gene expression data. These models will help in reducing the dimensionality and extracting meaningful features from the high-dimensional gene expression data.\n",
    "\n",
    "#### Shared Latent Space:\n",
    "After extracting features from each modality, we will map them to a shared latent space with aligned dimensionality. This shared latent space will allow us to jointly optimize the feature extraction process and the downstream predictive tasks. By aligning the dimensionality, we ensure that the features from different modalities can be effectively combined and compared.\n",
    "\n",
    "#### Fusion Strategies:\n",
    "We will explore different fusion strategies to integrate the latent features from each modality:\n",
    "- **Intermediate Fusion:** In this strategy, we will first learn latent features independently for each modality. Then, we will integrate these features through concatenation or attention layers. This approach allows us to capture the unique characteristics of each modality before combining them for the final prediction.\n",
    "\n",
    "By following this multimodal approach, we aim to harness the strengths of both chemical and transcriptomics data, leading to more accurate and reliable predictions in our downstream tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multimodal schema](https://blog.roboflow.com/content/images/2024/04/image-1203.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = MolGraphConvFeaturizer()\n",
    "\n",
    "# Training set\n",
    "train_chem_dataset = MoleculeDataset(\n",
    "    smiles_list = train_chem_df.values.flatten().tolist())\n",
    "train_chem_dataset.add_graphs(featurizer)\n",
    "logging.info(f\"Finished adding graphs: {len(train_chem_dataset.graphs_list)}\")\n",
    "\n",
    "# Validation set\n",
    "val_chem_dataset = MoleculeDataset(smiles_list = val_chem_df.values.flatten().tolist())\n",
    "val_chem_dataset.add_graphs(featurizer)\n",
    "\n",
    "# Test set\n",
    "test_chem_dataset = MoleculeDataset(smiles_list = test_chem_df.values.flatten().tolist())\n",
    "test_chem_dataset.add_graphs(featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_chem_loader = GeometricDataLoader(test_chem_dataset.graphs_list, batch_size=32)\n",
    "val_chem_loader = GeometricDataLoader(val_chem_dataset.graphs_list, batch_size=32)\n",
    "train_chem_loader = GeometricDataLoader(\n",
    "    train_chem_dataset.graphs_list, batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_combined_dataset = MultimodalDataset(train_chem_dataset, train_trans_dataset)\n",
    "train_combined_loader = DataLoader(train_combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Validation set\n",
    "val_combined_dataset = MultimodalDataset(val_chem_dataset, val_trans_dataset)\n",
    "val_combined_loader = DataLoader(val_combined_dataset, batch_size=32)\n",
    "\n",
    "# Test set\n",
    "test_combined_dataset = MultimodalDataset(test_chem_dataset, test_trans_dataset)\n",
    "test_combined_loader = DataLoader(test_combined_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define chemical model\n",
    "chem_model = GNN(\n",
    "    num_node_features=15,  \n",
    "    num_edge_features=13,  \n",
    "    hidden_dim=64,\n",
    "    output_dim=128,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "# Define transcriptomics model\n",
    "trans_model = TranscriptomicsNN(\n",
    "    input_dim=train_transcriptomics_df.shape[1],\n",
    "    hidden_dim=512,\n",
    "    output_dim=128,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "# Define multimodal model\n",
    "multimodal_model = MultimodalNN(\n",
    "    chem_output_dim=128,\n",
    "    trans_output_dim=128,\n",
    "    hidden_dim=256,\n",
    "    output_dim=1,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(chem_model.parameters())\n",
    "    + list(trans_model.parameters())\n",
    "    + list(multimodal_model.parameters()),\n",
    "    lr=0.001,\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from training.train_multimodal import evaluate_multimodal_model\n",
    "\n",
    "\n",
    "train_losses, val_losses = train_multimodal_model(\n",
    "    chem_model,\n",
    "    trans_model,\n",
    "    multimodal_model,\n",
    "    train_chem_loader,\n",
    "    train_trans_loader,\n",
    "    val_chem_loader,\n",
    "    val_trans_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device=device,\n",
    "    epochs=20, \n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, y_true, y_pred, metrics = evaluate_multimodal_model(\n",
    "    chem_model,\n",
    "    trans_model,\n",
    "    multimodal_model,\n",
    "    test_chem_loader,\n",
    "    test_trans_loader,\n",
    "    criterion,\n",
    "    device,\n",
    ")\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\n",
    "    f\"Test Loss: {test_loss:.4f}, \"\n",
    "    f\"MSE: {metrics['MSE']:.4f}, \"\n",
    "    f\"MAE: {metrics['MAE']:.4f}, \"\n",
    "    f\"R²: {metrics['R²']:.4f}, \"\n",
    "    f\"Pearson: {metrics['Pearson Correlation']:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the models dictionary for visualization\n",
    "models = {\n",
    "    \"Multimodal Model\": multimodal_model,\n",
    "}\n",
    "\n",
    "# Add train and validation losses to match the visualization structure\n",
    "train_losses_dict = {\"Multimodal Model\": train_losses}\n",
    "val_losses_dict = {\"Multimodal Model\": val_losses}\n",
    "\n",
    "# Call the unified visualization function\n",
    "# create_visualizations(\n",
    "#     models=models,\n",
    "#     X_test=None,\n",
    "#     y_test=y_test,\n",
    "#     train_losses=train_losses_dict,\n",
    "#     val_losses=val_losses_dict,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Test Loss: {test_loss:.4f}, \"\n",
    "    f\"MSE: {metrics['MSE']:.4f}, \"\n",
    "    f\"MAE: {metrics['MAE']:.4f}, \"\n",
    "    f\"R²: {metrics['R²']:.4f}, \"\n",
    "    f\"Pearson: {metrics['Pearson Correlation']:.4f}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5ARG45",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
