{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Training Pipeline Tutorial\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 08:51:45,844 - INFO - Enabling RDKit 2024.03.6 jupyter extensions\n",
      "2024-11-25 08:51:51,871 - INFO - TensorFlow version 2.13.0 available.\n",
      "2024-11-25 08:51:51,871 - INFO - PyTorch version 2.0.1+cpu available.\n",
      "2024-11-25 08:51:51,979 - INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from preprocess.preprocess import partition_data\n",
    "from preprocess.data_loader import prepare_chemical_data, prepare_transcriptomics_data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv(\"../data/processed/final_dataset.csv\")\n",
    "\n",
    "# Only select the first 100 rows for now\n",
    "combined_df = combined_df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    canonical_smiles\n",
      "0  COC(=O)C[C@](O)(CCCC(C)(C)O)C(=O)O[C@H]1[C@H]2...\n",
      "1  COC(=O)C[C@](O)(CCCC(C)(C)O)C(=O)O[C@H]1[C@H]2...\n",
      "2  COC(=O)C[C@](O)(CCCC(C)(C)O)C(=O)O[C@H]1[C@H]2...\n",
      "3  COC(=O)C[C@](O)(CCCC(C)(C)O)C(=O)O[C@H]1[C@H]2...\n",
      "4  COC(=O)C[C@](O)(CCCC(C)(C)O)C(=O)O[C@H]1[C@H]2...\n",
      "   viability\n",
      "0   0.372083\n",
      "1   0.410685\n",
      "2   0.825084\n",
      "3   0.698860\n",
      "4   0.516322\n",
      "          1         2         3         4         5         6         7  \\\n",
      "0  1.691468  0.372236 -1.314469 -1.930791 -0.211148 -2.320093 -2.142510   \n",
      "1  1.559223  0.320660 -1.116020 -1.846074 -0.547827 -1.222509 -1.477382   \n",
      "2  2.041255  0.981665  0.003209 -0.021115  0.119147 -0.250142  0.275295   \n",
      "3  0.966338 -0.417509 -0.633117  0.670356  0.388585 -0.558583 -1.565128   \n",
      "4  1.471947  0.221686 -1.640204 -2.127661  0.868745 -2.315318 -0.876314   \n",
      "\n",
      "          8         9        10  ...       673       674       675       676  \\\n",
      "0  0.876579  0.625576 -0.574647  ...  0.359634 -1.742530 -0.062960 -0.282645   \n",
      "1  0.318300  0.629693  0.418807  ... -0.326627 -1.547413 -0.730709  0.368457   \n",
      "2 -0.605215  0.229132  1.852584  ...  0.590408 -1.800547 -0.231119 -0.106020   \n",
      "3  0.350073  0.710889 -1.671000  ...  1.649204 -0.681197 -1.057065  0.345639   \n",
      "4  0.045980  1.052755  0.890627  ...  0.107529 -1.696292 -0.091665 -0.505295   \n",
      "\n",
      "        677       678       679       680       681       682  \n",
      "0  0.024090  0.006158 -0.276312  0.394939  1.288381  0.606827  \n",
      "1  0.448908 -0.729577 -0.079773  0.000381  1.599415  1.129405  \n",
      "2  1.334879  0.409039  1.285532 -0.359685  1.235453  0.461526  \n",
      "3  1.722410  0.952792  0.483664  0.200859  1.308660 -0.270612  \n",
      "4  0.511775  0.359123  0.035256 -0.802694  0.921919  0.216087  \n",
      "\n",
      "[5 rows x 682 columns]\n"
     ]
    }
   ],
   "source": [
    "chem_df, viability_df, transcriptomics_df = partition_data(combined_df)\n",
    "\n",
    "print(chem_df.head())\n",
    "print(viability_df.head())\n",
    "print(transcriptomics_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Replace 'column_name' with the actual column name you want to convert to a list\n",
    "smiles_list = chem_df['canonical_smiles'].tolist()\n",
    "targets = viability_df[\"viability\"].tolist()\n",
    "print(len(smiles_list))\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[78, 15], edge_index=[2, 164], edge_attr=[164, 13])\n"
     ]
    }
   ],
   "source": [
    "from preprocess.molecule_graph import mol_to_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example continuous features for fitting\n",
    "features = np.array([[0.1, 1, 0, 2], [0.2, 2, -1, 1]])\n",
    "\n",
    "# Initialize and fit the scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features)\n",
    "\n",
    "graph = mol_to_graph(smiles_list[0], scaler)\n",
    "\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 valid graphs out of 1000 SMILES\n"
     ]
    }
   ],
   "source": [
    "chem_data_loader = prepare_chemical_data(smiles_list, targets, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptomics_data_loader = prepare_transcriptomics_data(\n",
    "        transcriptomics_df, targets, batch_size=32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[66, 15], edge_index=[2, 140], edge_attr=[140, 13], y=[1])\n"
     ]
    }
   ],
   "source": [
    "for i, chem_data in enumerate(chem_data_loader):\n",
    "    print(chem_data[9])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the models!\n",
      "Starting epoch 1\n",
      "Epoch 1, Loss: 0.2917\n",
      "Starting epoch 2\n",
      "Epoch 2, Loss: 0.0892\n",
      "Starting epoch 3\n",
      "Epoch 3, Loss: 0.0680\n",
      "Starting epoch 4\n",
      "Epoch 4, Loss: 0.0560\n",
      "Starting epoch 5\n",
      "Epoch 5, Loss: 0.0468\n",
      "Starting epoch 6\n",
      "Epoch 6, Loss: 0.0388\n",
      "Starting epoch 7\n",
      "Epoch 7, Loss: 0.0358\n",
      "Starting epoch 8\n",
      "Epoch 8, Loss: 0.0398\n",
      "Starting epoch 9\n",
      "Epoch 9, Loss: 0.0368\n",
      "Starting epoch 10\n",
      "Epoch 10, Loss: 0.0320\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from models.gnn import GNN\n",
    "from models.multimodal_nn import MultimodalNN\n",
    "from models.transcriptomics_nn import TranscriptomicsNN\n",
    "from training.train_multimodal import train_multimodal_model\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load data\n",
    "# final_df = pd.read_csv(\"data/processed/final_dataset.csv\")\n",
    "# chem_df, viability_df, transcriptomics_df = partition_data(final_df)\n",
    "\n",
    "# # Prepare chemical data\n",
    "# smiles_list = chem_df[\"canonical_smiles\"].tolist()\n",
    "# targets = viability_df[\"viability\"].tolist()\n",
    "# chem_data_loader = prepare_chemical_data(smiles_list, targets, batch_size=32)\n",
    "\n",
    "# # Prepare transcriptomics data\n",
    "# transcriptomics_data_loader = prepare_transcriptomics_data(\n",
    "#     transcriptomics_df, targets, batch_size=32\n",
    "# )\n",
    "\n",
    "# Initialize models\n",
    "num_node_features = 15\n",
    "num_edge_features = 13\n",
    "\n",
    "chem_model = GNN(\n",
    "    num_node_features=num_node_features,\n",
    "    num_edge_features=num_edge_features,\n",
    "    hidden_dim=64,\n",
    "    output_dim=128,\n",
    "    dropout=0.1,  # If applicable\n",
    ").to(device)\n",
    "\n",
    "trans_model = TranscriptomicsNN(\n",
    "    input_dim=transcriptomics_df.shape[1],\n",
    "    hidden_dim=512,\n",
    "    output_dim=128,\n",
    "    dropout=0.1,  # If applicable\n",
    ").to(device)\n",
    "\n",
    "multimodal_model = MultimodalNN(\n",
    "    chem_output_dim=128,\n",
    "    trans_output_dim=128,\n",
    "    hidden_dim=256,\n",
    "    output_dim=1,\n",
    "    dropout=0.1,  # If applicable\n",
    ").to(device)\n",
    "\n",
    "# Initialize optimizer and loss function\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(chem_model.parameters())\n",
    "    + list(trans_model.parameters())\n",
    "    + list(multimodal_model.parameters()),\n",
    "    lr=0.001,\n",
    ")\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "print(\"Start training the models!\")\n",
    "\n",
    "# Train the model\n",
    "train_multimodal_model(\n",
    "    chem_model,\n",
    "    trans_model,\n",
    "    multimodal_model,\n",
    "    chem_data_loader,\n",
    "    transcriptomics_data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    epochs=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
